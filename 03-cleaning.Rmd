```{r,echo = FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)

```

# Data transformation

In this section, we are going to load our dataset and clean it. There are five main steps to transform the dataset: 1) download the csv files from the NYCD OpenData and extract data only from a specific time interval, 2) continue to select a proportion of variables to avoid unnecessary data, 3) detect the missing values in the dataset and replace them with "NA", 4) add or remove some variables that may be helpful to conduct our analyses, and 5) change the orders of factor levels or some character's names so that they can be easily understood.


## COVID-19 Dataset

This file contains information on the number and estimated percentage of NYC residents fully vaccinated and residents who received at least one dose of COVID-19 vaccine by Modified ZCTA (MODZCTA). Percentages of NYC residents vaccinated is calculated against the estimated total population of the specified MODZCTA.

Note that the number of people vaccinated may exceed the estimated population and lead to more than 100% vaccination coverage, especially for smaller demographic categories and geographies. 

Since the dataset provided is already clean, we only need to extracted the necessary columns that are mentioned in the previous chapter. 

```{R,echo = FALSE}
coverage = data.frame(read_csv('data/coverage-by-boro-demo.csv')) %>% select('BOROUGH','AGE_GROUP','RACE_ETHNICITY','PERC_FULLY','PERC_1PLUS')
```

## Crime Dataset

### Shooting Incident Data

After downloading the csv file from the website, we combine the NYPD Shooting Incident Data (Historic) and the NYPD Shooting Incident Data (Year to Date). Since we are more confused on people's living condition in New York city during the pandemic, we only select data from 2020-01-01 to 2021-09-30 and export it a csv file. We consider `BORO`, `LOCATION_DESC`, `OCCUR_DATE`, `OCCUR_TIME`, `STATISTICAL_MURDER_FLAG`, `VIC_AGE_GROUP`, `VIC_RACE`, and `VIC_SEX` as important variables and remove the remaining variables. We also change each name for the `BORO` column to make it more readable.

```{r,echo = FALSE}
shooting_df <- read_csv('data/NYPD_Shooting_2020_2021.csv', na = c("", "UNKNOWN"), show_col_types = FALSE) %>%
  select(-c('PRECINCT', 'PERP_AGE_GROUP', 'PERP_RACE', 'PERP_SEX')) %>% 
  mutate(BORO = case_when(BORO == 'BRONX' ~ 'Bronx',
                   BORO == 'STATEN ISLAND' ~ 'Staten Island',
                   BORO == 'BROOKLYN' ~ 'Brooklyn',
                   BORO == 'MANHATTAN' ~ 'Manhattan',
                   BORO == 'QUEENS' ~ 'Queens'))
summary(shooting_df)
head(shooting_df)
```

### Arrest Data

We follow the similar steps as shown before by combining the NYPD Arrest Data Data (Historic) and the NYPD Arrest Data Data (Year to Date). We only select data from 2020-01-01 to 2021-09-30 to keep it consistent with the shooting incident dataset and export it a csv file. We consider `ARREST_BORO`, `ARREST_DATE`, `LAW_CAT_CD`, `OFNS_DESC`, and `PD_DESC` as important variables. We also add three new variables `ArrestYear`, `ARREST_MONTH`, and `ARREST_WEEKDAY`.

```{r,echo = FALSE}
arrest_df <- read_csv('data/NYPD_Arrest_2020_2021.csv', na = c("", "UNKNOWN"), show_col_types = FALSE) %>%
  select('ARREST_BORO', 'ARREST_DATE', 'LAW_CAT_CD', 'OFNS_DESC', 'PD_DESC')
arrest_df$ARREST_DATE <- as.Date(arrest_df$ARREST_DATE, format = "%m/%d/%y")
arrest_df <- arrest_df %>% 
  mutate(ArrestYear = factor(as.numeric(format(ARREST_DATE,'%Y'))),
         ARREST_MONTH = as.numeric(format(ARREST_DATE,'%m')),
         ARREST_WEEKDAY = weekdays(ARREST_DATE),
         ARREST_WEEKDAY = case_when(ARREST_WEEKDAY == 'Monday' ~ 'Mon',
                                    ARREST_WEEKDAY == 'Tuesday' ~ 'Tue',
                                    ARREST_WEEKDAY == 'Wednesday' ~ 'Wed',
                                    ARREST_WEEKDAY == 'Thursday' ~ 'Thr',
                                    ARREST_WEEKDAY == 'Friday' ~ 'Fri',
                                    ARREST_WEEKDAY == 'Saturday' ~ 'Sat',
                                    ARREST_WEEKDAY == 'Sunday' ~ 'Sun'),
         ARREST_BORO = case_when(ARREST_BORO == 'B' ~ 'Bronx',
                                 ARREST_BORO == 'S' ~ 'Staten Island',
                                 ARREST_BORO == 'K' ~ 'Brooklyn',
                                 ARREST_BORO == 'M' ~ 'Manhattan',
                                 ARREST_BORO == 'Q' ~ 'Queens'),
         LAW_CAT_CD = case_when(LAW_CAT_CD == 'F' ~ 'Felony',
                                 LAW_CAT_CD == 'M' ~ 'Misdemeanor',
                                 LAW_CAT_CD == 'V' ~ 'Violation',
                                 LAW_CAT_CD == 'I' ~ 'Infraction'))
summary(arrest_df)
head(arrest_df)
```


## Air Quality Dataset

We first extracted the necessary columns that are mentioned in the previous chapter. Then we notice that in the `Measure` column, there are only two values, we only use Mean as out measure since there are not enough data for the other one.

```{r,echo = FALSE}
air_qua = data.frame(read_csv('data/Air_Quality_2016_2018.csv') %>% select('Name', 'Measure', 'Geo Join ID', 'Start_Date', 'Data Value'))
air_quality = air_qua
knitr::kable(as.data.frame(table(air_quality$Measure)), caption = "Measure Counts",row.names = F,font_size = 10)
air_quality = air_quality %>% filter(Measure =='Mean')
```
In the `Measure` column, there are only three values. After counting the numbers of different values, we decide not to remove any values.


```{r, echo = FALSE}
knitr::kable(as.data.frame(table(air_quality$Name)), caption = "Measure Counts",row.names = F,font_size = 10)
```

After removing some observations, we notice that in this data, there are hundreds of values in  `Neighborhood name` columns, we need to use the `Geo Join ID` column to classify them into different boroughs. The `Geo Join ID` variable is the identifier of the neighborhood geographic area, which is a three or six digits number. The first digit represents different boroughs.


```{r,echo = FALSE}
air_quality$Borough = 'Bronx'
air_quality$Geo.Join.ID = as.character(air_quality$Geo.Join.ID)
for(i in 1:nrow(air_quality)){
  tmp = substr(air_quality[i,3],1,1)
  if(tmp == '2'){
    air_quality[i,6] = 'Brooklyn'
  }
  if(tmp == '3'){
    air_quality[i,6] = 'Manhattan'
  }
  if(tmp == '4'){
    air_quality[i,6] = 'Queens'
  }
  if(tmp == '5'){
    air_quality[i,6] = 'Staten Island'
  }
}
ggplot(air_quality, aes(x = fct_relevel(Borough,'Manhattan','Brooklyn','Queens','Bronx'))) +
  geom_histogram(stat="count")+
  xlab('Borough')+
  ylab('Count')+
  ggtitle('Number of observations in different boroughs')
  
```

From the histogram above we can see that after classification, the dataset seems to be pretty balanced.
